{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MEG2GAN_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satoruk-icepp/MEG2XEC/blob/master/MEG2GAN_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT7Rky0ngCyq",
        "colab_type": "code",
        "outputId": "e2f6e074-6e53-4a41-88c8-2e2dddafa97e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXxnaK7TH6vO",
        "colab_type": "code",
        "outputId": "9c3900af-e530-410b-f0f1-1e117918547f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile .comet.config\n",
        "[comet]\n",
        "api_key=mIel5ZAPOioTs0Cij75dSSQXs\n",
        "logging_file = /tmp/comet.log\n",
        "logging_file_level = info\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing .comet.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlDzipgxH9kV",
        "colab_type": "code",
        "outputId": "f5b55b94-0f58-47ee-f5c0-b267dfff2f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install skorch comet_ml\n",
        "!pip install uproot"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/1e/cc4e1f23cd1faab06672f309e0857294aaa80c5f84670f4d3d19b08ab10b/skorch-0.7.0-py3-none-any.whl (105kB)\n",
            "\r\u001b[K     |███                             | 10kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 2.8MB/s \n",
            "\u001b[?25hCollecting comet_ml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/c6/fac88f43f2aa61a09fee4ffb769c73fe93fe7de75764246e70967d31da09/comet_ml-3.0.2-py3-none-any.whl (170kB)\n",
            "\r\u001b[K     |██                              | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40kB 25.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51kB 26.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 61kB 28.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 71kB 28.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81kB 28.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 92kB 29.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 102kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 112kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 122kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 143kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 153kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 163kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.17.4)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.3.3)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.28.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.21.3)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
            "Collecting everett[ini]>=1.0.1; python_version >= \"3.0\"\n",
            "  Downloading https://files.pythonhosted.org/packages/12/34/de70a3d913411e40ce84966f085b5da0c6df741e28c86721114dd290aaa0/everett-1.0.2-py2.py3-none-any.whl\n",
            "Collecting comet-git-pure>=0.19.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/91/b191ae375380332f82aaa83a41c45844ee1809198085cd267fbcb95cce86/comet_git_pure-0.19.14-py3-none-any.whl (401kB)\n",
            "\u001b[K     |████████████████████████████████| 409kB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n",
            "Collecting wurlitzer>=1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/24/5e/f3bd8443bfdf96d2f5d10097d301076a9eb55637b7864e52d2d1a4d8c72a/wurlitzer-2.0.0-py2.py3-none-any.whl\n",
            "Collecting netifaces>=0.10.7\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/9b/c4c7eb09189548d45939a3d3a6b3d53979c67d124459b27a094c365c347f/netifaces-0.10.9-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting websocket-client>=0.55.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.14.1)\n",
            "Collecting configobj; extra == \"ini\"\n",
            "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (2019.11.28)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.8)\n",
            "Building wheels for collected packages: configobj\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34546 sha256=abbe4a401d8258e600d83a4426650755ead82e08b1c6ea06b7544af388145bf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n",
            "Successfully built configobj\n",
            "Installing collected packages: skorch, configobj, everett, comet-git-pure, wurlitzer, netifaces, websocket-client, comet-ml\n",
            "Successfully installed comet-git-pure-0.19.14 comet-ml-3.0.2 configobj-5.0.6 everett-1.0.2 netifaces-0.10.9 skorch-0.7.0 websocket-client-0.57.0 wurlitzer-2.0.0\n",
            "Collecting uproot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/42/1d78f017dce5b5679b3ac4485db7ecfeca121df92cfb6cfe9d07569eae9b/uproot-3.11.0-py2.py3-none-any.whl (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.6/dist-packages (from uproot) (4.0.0)\n",
            "Collecting awkward<1.0,>=0.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f3/d86d52275cfe131692c89558a22187e40cf111485154affac74d7509ee43/awkward-0.12.19-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from uproot) (1.17.4)\n",
            "Collecting uproot-methods>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/39/7867f279a8ca8a67ae8ca56c371dda6cc8e05dc01ac614f05586c857dfe2/uproot_methods-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: awkward, uproot-methods, uproot\n",
            "Successfully installed awkward-0.12.19 uproot-3.11.0 uproot-methods-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLgVy1i9zZiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# N_EPOCH            = 200\n",
        "\n",
        "N=50250\n",
        "Nval = 500\n",
        "NOISEIMAGE_DIM = 4\n",
        "NOISE_DIM = NOISEIMAGE_DIM**2\n",
        "\n",
        "# do_reg = False\n",
        "# use_resblock = True\n",
        "params={'batch_size' : 64,\n",
        "        'data_size'  : 32000,\n",
        "        'epochs'     : 500,\n",
        "        'noise_dim'   : NOISE_DIM,\n",
        "        'noiselevel'  : 0.0001,\n",
        "        'dropout_conv':0.3,\n",
        "        'dropout_gen':0.0,\n",
        "        'unrolled_steps':0,\n",
        "        'alpha':0.1,\n",
        "        'ntrain_d':5,\n",
        "        'lambda_reg':100,\n",
        "        # 'task':\"WASSERSTEIN\",\n",
        "        # 'task':\"NORMAL\",\n",
        "        'task':\"HINGE\",\n",
        "        'gp':False,\n",
        "        'lipsitzbound':0.01,\n",
        "        'optimizer':'Adam',\n",
        "        # 'optimizer':'RMSProp',\n",
        "        'learning_rate':1e-04,\n",
        "        'lrratio':1,\n",
        "        'weight_decay':1e-05,\n",
        "        'restartfrom':0,\n",
        "        'stepsize_lr':1, # for lr_test\n",
        "        \"LRtype\":\"Step\",\n",
        "        # 'learning_rate':0.01,\n",
        "        # 'LRgamma':0.3,\n",
        "        'LRgamma':1,\n",
        "        'milestones':[200,400,600,800,1000],\n",
        "        'stepsize_lr_down':29,\n",
        "        'base_lr':0.000001,\n",
        "        'conditional':True,\n",
        "        'test_sample':False\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6CjhrWKT4Ig",
        "colab_type": "code",
        "outputId": "f8209255-076c-4cc0-80b6-eed4a195dc71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from comet_ml import Experiment\n",
        "experiment = Experiment(project_name=\"CWGAN\")\n",
        "experiment.log_parameters(params)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/satoruk-icepp/cwgan/3e2858c7648b44469433be701082db3a\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLY8nIkZLn24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skorch import NeuralNetClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "790_h5rSmDLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as utils\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import MultiStepLR,StepLR,CyclicLR,CosineAnnealingLR\n",
        "import uproot\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "sns.set()\n",
        "\n",
        "def one_hot(a, num_classes):\n",
        "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW0lyRVGmDLC",
        "colab_type": "code",
        "outputId": "73bdf137-2cdd-4232-bc30-eb09767ef4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExAROHySmDLP",
        "colab_type": "text"
      },
      "source": [
        "## Load it to pytorch `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZHvia9vcRYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = uproot.open(\"/content/drive/My Drive/MEG2CW/test.root\")\n",
        "tout = file[\"tout\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8kq9xIYcUPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Energy  = tout.array(\"energy\").reshape(-1,1)\n",
        "EneREC  = tout.array(\"nsum2\").reshape(-1,1)\n",
        "UVW     = tout.array(\"uvw_MC\").reshape(-1,3)\n",
        "DIR     = tout.array(\"gamangle\").reshape(-1,2)\n",
        "SHW     = tout.array(\"shw_vec\").reshape(-1,3)\n",
        "UVWREC  = tout.array(\"uvw_rec\").reshape(-1,3)\n",
        "PMResponse = tout.array(\"Npho\").reshape(-1,4760)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99o5Ls6QgZke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PMResponse_MPPC, PMResponse_PMT = np.split(PMResponse,[4092],axis=1)\n",
        "PMResponse_MPPC = PMResponse_MPPC.reshape(PMResponse.shape[0],1,93,44)\n",
        "PMResponse_MPPC = PMResponse_MPPC/20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xjjn87Bgp5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.hist(PMResponse_MPPC[:200].reshape(-1,4092))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKLH_dKnc_rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Energy        = torch.tensor(Energy).float()\n",
        "# EneREC        = torch.tensor(EneREC).float()\n",
        "UVW           = torch.tensor(UVW).float()\n",
        "DIR           = torch.tensor(DIR).float()\n",
        "SHW           = torch.tensor(SHW).float()\n",
        "# ADD           = torch.tensor(ADD).float()\n",
        "# UVWREC        = torch.tensor(UVWREC).float()\n",
        "PMResponse    = torch.tensor(PMResponse_MPPC).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_R_16T78En1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del PMResponse_MPPC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtEr15sdmDLQ",
        "colab_type": "code",
        "outputId": "19b1a7e7-6a63-42a0-e355-d57a557408ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "# validation_split = 0.05\n",
        "random_seed= 42\n",
        "split =params[\"batch_size\"]\n",
        "if params[\"data_size\"]>0:\n",
        "    indices = list(range(params[\"data_size\"]))\n",
        "else:\n",
        "    indices = list(range(Energy.shape[0]))\n",
        "print(len(indices))\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "calo_dataset    = utils.TensorDataset(Energy,UVW,SHW,PMResponse)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(calo_dataset, batch_size=params[\"batch_size\"], \n",
        "                                           sampler=train_sampler, pin_memory=True)\n",
        "validation_loader = torch.utils.data.DataLoader(calo_dataset, batch_size=params[\"batch_size\"],\n",
        "                                                sampler=valid_sampler, pin_memory=True)\n",
        "\n",
        "\n",
        "# calo_dataloader = torch.utils.data.DataLoader(calo_dataset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crC_kDGkmDLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for Energy_b, UVW_b, SHW_b, PMResponse_b in validation_loader:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcjTzQ9w0a8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Make_Sample(batch_size,x_size,y_size):\n",
        "    x = torch.randint(int(0.25*x_size),int(0.75*x_size),(batch_size,))\n",
        "    y = torch.randint(int(0.25*y_size),int(0.75*y_size),(batch_size,))\n",
        "    z = torch.randint(1,5,(batch_size,))\n",
        "    tensor = torch.zeros([batch_size,1,93, 44], dtype=torch.float)\n",
        "    for i in range(batch_size):\n",
        "        tensor[i,0,x[i]-z[i]:x[i]+z[i],y[i]-z[i]:y[i]+z[i]]=0.4\n",
        "    # tensor[:,:,x,y]=1\n",
        "    # print(tensor[:,:,x,y])\n",
        "    # print(tensor)\n",
        "    return tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwFLHo5j3mz2",
        "colab_type": "code",
        "outputId": "9f2f531b-e095-4549-d593-790d6716c653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "sample= Make_Sample(3,93,44)\n",
        "# print(sample)\n",
        "plt.imshow(sample[0][0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1b851a6d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIwAAAD+CAYAAADoKu30AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAxMCAYmBAMTgoEJwcCEYGDyX11UzqleekOuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inm6pj7DmDLU",
        "colab_type": "text"
      },
      "source": [
        "## Training GAN\n",
        "###### ...is not a simple matter\n",
        "\n",
        "It depends on architecture, loss, instance noise, augmentation and even luck(recommend to take a look https://arxiv.org/pdf/1801.04406.pdf)\n",
        "\n",
        "\n",
        "In this notebook I have prepared some basic parts that you could use for your experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNKTOTNkmDLb",
        "colab_type": "text"
      },
      "source": [
        "#### Small hack that can speed-up training and improve generalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_qOnCr6Zias",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from bayes import NoiseLoss,PriorLoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4ttB8J3UqR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_instance_noise(data, std=0.01):\n",
        "    return data + torch.distributions.Normal(0, std).sample(data.shape).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iBaXyY13Xtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class GANLosses(object):\n",
        "#     def __init__(self, task, device):\n",
        "#         self.TASK = task\n",
        "#         self.device = device\n",
        "def critic(disc_1,disc_2):\n",
        "    return (torch.norm(disc_1 - disc_2,p=2,dim=-1) - torch.norm(disc_1,p=2,dim=-1)).mean()\n",
        "\n",
        "def gen_loss_func(disc_real,disc_gen_1,disc_gen_2):\n",
        "    return (torch.norm(disc_real - disc_gen_1,p=2,dim=-1) + \n",
        "            torch.norm(disc_real - disc_gen_2,p=2,dim=-1) -\n",
        "            torch.norm(disc_gen_1 - disc_gen_2,p=2,dim=-1)\n",
        "           ).mean()\n",
        "\n",
        "def calc_gradient_penalty(discriminator, data_gen, inp_data,condition=None, lambda_reg = .1):\n",
        "        alpha = torch.rand(inp_data.shape[0], 1).to(device)\n",
        "        dims_to_add = len(inp_data.size()) - 2\n",
        "        for i in range(dims_to_add):\n",
        "            alpha = alpha.unsqueeze(-1)\n",
        "        # alpha = alpha.expand(inp_data.size())\n",
        "\n",
        "        interpolates = (alpha * inp_data + ((1 - alpha) * data_gen)).to(device)\n",
        "\n",
        "        interpolates.requires_grad = True\n",
        "\n",
        "        disc_interpolates,_ = discriminator(interpolates,condition)\n",
        "\n",
        "        gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                                        grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
        "                                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lambda_reg\n",
        "        return gradient_penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT8YWKN5mDLg",
        "colab_type": "text"
      },
      "source": [
        "## Defining discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4_WffK-mDLi",
        "colab_type": "text"
      },
      "source": [
        "## Defining generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD3j9qwIe9MG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import Label2Image\n",
        "# from generator import ModelGConvTranspose\n",
        "# from discriminator import ModelD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnGGL4G_hoSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, (nn.Linear, nn.Conv2d, nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        if m.bias.data is not None:\n",
        "            m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FNzYdMphBMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,input_size):\n",
        "        super(ResidualBlock, self).__init__()        \n",
        "        self.conv1 = nn.Conv2d(input_size,input_size,3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(input_size,input_size,3,padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(self.conv1.out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(self.conv2.out_channels)        \n",
        "        self.activation = nn.LeakyReLU(0.0)\n",
        "    def forward(self,xraw):\n",
        "        x = self.activation(self.bn1(self.conv1(xraw)))\n",
        "        x = self.activation(self.bn2(self.conv2(x))+xraw)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXi0xkNng90u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReducedConv(nn.Module):\n",
        "    def __init__(self,input_size,output_size, input_dim, output_dim,kernel_size):\n",
        "        super(ReducedConv, self).__init__()\n",
        "        eps = 1e-3\n",
        "        scale = float(output_dim+kernel_size-3+eps)/float(input_dim)\n",
        "        self.ups = nn.Upsample(scale_factor = scale,mode = 'bilinear',align_corners=False )\n",
        "        self.ref = nn.ReflectionPad2d(1)\n",
        "        self.conv = nn.Conv2d(input_size,output_size,kernel_size)\n",
        "        self.in_channels = input_size\n",
        "        self.out_channels = output_size\n",
        "    def forward(self,x):\n",
        "        return self.conv(self.ref(self.ups(x)))\n",
        "\n",
        "class ReducedConv2(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,scale_factor,kernel_size):\n",
        "        super(ReducedConv2, self).__init__()\n",
        "        eps = 1e-3\n",
        "        self.ups = nn.Upsample(scale_factor = scale_factor,mode = 'bilinear',align_corners=False )\n",
        "        self.ref = nn.ReflectionPad2d(1)\n",
        "        self.conv = nn.Conv2d(in_channels,out_channels,kernel_size)\n",
        "        self.conv = spectral_norm(self.conv)\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "    def forward(self,x):\n",
        "        return self.conv(self.ref(self.ups(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D02ZgiS7yCz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(net):\n",
        "    with torch.no_grad(): \n",
        "        if type(net) == nn.Linear:\n",
        "            torch.nn.init.xavier_normal_(net.weight)\n",
        "            net.bias.data.fill_(0.001)\n",
        "        if type(net) == nn.Conv2d:\n",
        "            torch.nn.init.xavier_uniform_(net.weight)\n",
        "            net.bias.data.fill_(0.001)\n",
        "        if type(net) == nn.ConvTranspose2d:\n",
        "            torch.nn.init.xavier_uniform_(net.weight)\n",
        "            net.bias.data.fill_(0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46lQ7--5Z3r0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self,dropout_gen=0., Ndim_cond=0,alpha=0.):\n",
        "        super(Generator, self).__init__()\n",
        "        self.Ndim_cond = Ndim_cond\n",
        "        self.fc1 = nn.Linear(NOISEIMAGE_DIM**2+self.Ndim_cond,256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features,36*64)\n",
        "        # self.rc1 = ReducedConv(16,8,16,32,3)\n",
        "        # self.rc2 = ReducedConv(8,4,32,100,3)\n",
        "        # self.deconv1 = nn.ConvTranspose2d(64,32,stride=2,kernel_size=2)#(6,6)->(12,12)\n",
        "        # self.deconv2 = nn.ConvTranspose2d(32,16,stride=(3,2),kernel_size=(3,4),padding=(2,1))##(12,12)->(36,24)\n",
        "        # self.deconv3 = nn.ConvTranspose2d(16,1,stride=(3,2),kernel_size=(6,4),padding=3)##(36,24)->(93,44)\n",
        "        self.deconv1 = ReducedConv2(64,32,2,4)#(6,6)->(11,11)\n",
        "        self.deconv2 = ReducedConv2(32,16,(3,2),3)#(11,11)->(33,22)\n",
        "        self.deconv3 = ReducedConv2(16,1,(3,2),(9,3))#(33,22)->(93,44)\n",
        "        # self.deconv1 = spectral_norm(self.deconv1)\n",
        "        # self.deconv2 = spectral_norm(self.deconv2)\n",
        "        # self.deconv3 = spectral_norm(self.deconv3)\n",
        "        self.bn1=nn.BatchNorm2d(self.deconv1.out_channels)\n",
        "        self.bn2=nn.BatchNorm2d(self.deconv2.out_channels)\n",
        "        self.dropout = nn.Dropout(dropout_gen)\n",
        "        self.activation  = nn.LeakyReLU(alpha)\n",
        "\n",
        "    def forward(self,x,condition=None):\n",
        "        x = x.view(-1,NOISEIMAGE_DIM**2)\n",
        "        if condition is not None and self.Ndim_cond>0:\n",
        "            x = torch.cat([x,condition],dim=1)\n",
        "        \n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = x.view(-1,64,6,6)\n",
        "        x = self.activation(self.dropout(self.bn1(self.deconv1(x))))\n",
        "        x = self.activation(self.dropout(self.bn2(self.deconv2(x))))\n",
        "        x = self.deconv3(x)\n",
        "        return torch.tanh(x)\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ulrOSPa4l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,dropout_conv=0.0, Ndim_cond=0,alpha=0.):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # self.rconv1 = ReducedConv(1,Nlayer,)\n",
        "        self.Ndim_cond = Ndim_cond\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            1, \n",
        "            16, \n",
        "            kernel_size=(6,4), \n",
        "            padding = 3,\n",
        "            stride = (3,2)\n",
        "        )#(93+4,44+4)->95,46\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            self.conv1.out_channels, \n",
        "            self.conv1.out_channels*2, \n",
        "            kernel_size=(3, 4), \n",
        "            stride=(3,2),\n",
        "            padding=(2,1)\n",
        "        )#95,46->46*22\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            self.conv2.out_channels, \n",
        "            self.conv2.out_channels*2, \n",
        "            kernel_size=2,\n",
        "            stride=2\n",
        "        )#46*22->22,10\n",
        "        self.conv1 = spectral_norm(self.conv1)\n",
        "        self.conv2 = spectral_norm(self.conv2)\n",
        "        self.conv3 = spectral_norm(self.conv3)\n",
        "        self.lnorm1 = nn.LayerNorm([self.conv1.out_channels,32,24])\n",
        "        self.lnorm2 = nn.LayerNorm([self.conv2.out_channels,12,12])\n",
        "        self.lnorm3 = nn.LayerNorm([self.conv3.out_channels,6,6])\n",
        "        self.fcstart = nn.Linear(self.conv3.out_channels*36+self.Ndim_cond,256)\n",
        "        self.fcend = nn.Linear(self.fcstart.out_features,1)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(dropout_conv)\n",
        "        self.activation  = nn.LeakyReLU(alpha)\n",
        "        # self.dropoutfc = nn.Dropout(dropout_fc)\n",
        "        # self.Nresblock = Nresblock\n",
        "        # self.Nsd = Nsd\n",
        "        \n",
        "    def forward(self, x,condition=None):\n",
        "        x_mppc = x.view(x.shape[0],1,93,44)\n",
        "        x_mppc = self.activation(self.conv1(x_mppc))\n",
        "        x_mppc = self.activation(self.dropout1(self.conv2(x_mppc)))\n",
        "        x_mppc = self.activation(self.dropout1(self.conv3(x_mppc)))\n",
        "        # x_mppc = F.relu(self.dropout1(self.conv4(x_mppc)))\n",
        "\n",
        "        x = x_mppc.view(x_mppc.shape[0],-1)\n",
        "        if condition is not None:\n",
        "            x = torch.cat([x,condition],dim=1)\n",
        "        x = self.activation(self.fcstart(x))\n",
        "        x = self.fcend(x)\n",
        "        return x,torch.sigmoid(x)\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys1Z545TmDLl",
        "colab_type": "text"
      },
      "source": [
        "## Check our models on one batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe748y6nmDLl",
        "colab_type": "code",
        "outputId": "f4cc8245-9e9f-479e-f074-82a784158fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "\n",
        "gens = []\n",
        "discs = []\n",
        "\n",
        "if params[\"conditional\"]:\n",
        "    gen  = Generator(params[\"dropout_gen\"],3,params[\"alpha\"]).to(device)\n",
        "    disc = Discriminator(params[\"dropout_conv\"],3,params[\"alpha\"]).to(device)\n",
        "else:\n",
        "    gen  = Generator(params[\"dropout_gen\"],0,params[\"alpha\"]).to(device)\n",
        "    disc = Discriminator(params[\"dropout_conv\"],0,params[\"alpha\"]).to(device)\n",
        "\n",
        "gen.apply(init_weights)\n",
        "disc.apply(init_weights)\n",
        "\n",
        "# gen.weight_init(mean=0.0, std=0.02)\n",
        "# disc.weight_init(mean=0.0, std=0.02)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(6, 4), stride=(3, 2), padding=(3, 3))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 4), stride=(3, 2), padding=(2, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (lnorm1): LayerNorm((16, 32, 24), eps=1e-05, elementwise_affine=True)\n",
              "  (lnorm2): LayerNorm((32, 12, 12), eps=1e-05, elementwise_affine=True)\n",
              "  (lnorm3): LayerNorm((64, 6, 6), eps=1e-05, elementwise_affine=True)\n",
              "  (fcstart): Linear(in_features=2307, out_features=256, bias=True)\n",
              "  (fcend): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (dropout1): Dropout(p=0.3, inplace=False)\n",
              "  (activation): LeakyReLU(negative_slope=0.1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2y2Q4Rb4YUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "class CosineExpLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, T_max, eta_min=0, gamma=0.99, last_epoch=-1):\n",
        "            self.T_max = T_max\n",
        "            self.eta_min = eta_min\n",
        "            # self.decayconst = decayconst\n",
        "            self.gamma = gamma\n",
        "            super(CosineExpLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        return [self.gamma ** self.last_epoch*(self.eta_min + (base_lr - self.eta_min) *\n",
        "                (1 + math.cos(math.pi * self.last_epoch / self.T_max)) / 2)\n",
        "                for base_lr in self.base_lrs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgnGKjGF4MPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reg_loss = torch.nn.SmoothL1Loss().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "# gprior_criterion = PriorLoss(prior_std=1., observed=N)\n",
        "# gnoise_criterion = NoiseLoss(params=gen.parameters(), noise_std=math.sqrt(2 * gnoise_alpha * learning_rate), observed=N)\n",
        "# dprior_criterion = PriorLoss(prior_std=1., observed=N)\n",
        "# dnoise_criterion = NoiseLoss(params=disc.parameters(), noise_std=math.sqrt(2 * dnoise_alpha * learning_rate), observed=N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCaPksu4mDLz",
        "colab_type": "text"
      },
      "source": [
        "## Defining optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXVckXSZmDL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if params[\"optimizer\"] == \"Adam\":\n",
        "    gen_opt  = optim.Adam(gen.parameters() , lr=params[\"learning_rate\"], betas=(0.9, 0.999), weight_decay=params[\"weight_decay\"])\n",
        "    disc_opt = optim.Adam(disc.parameters(), lr=params[\"learning_rate\"]*params[\"lrratio\"], betas=(0.9, 0.999), weight_decay=params[\"weight_decay\"])\n",
        "    # reg_gen_opt = optim.Adam(gen.parameters(), lr=params[\"learning_rate_reg\"], betas=(0.9,0.999))\n",
        "    # reg_disc_opt = optim.Adam(disc.parameters(), lr=params[\"learning_rate_reg\"], betas=(0.9,0.999))\n",
        "    \n",
        "elif params[\"optimizer\"] == \"RMSProp\":\n",
        "    gen_opt  = optim.RMSprop(gen.parameters(), lr=params[\"learning_rate\"],weight_decay=params[\"weight_decay\"])\n",
        "    disc_opt = optim.RMSprop(disc.parameters(), lr=params[\"learning_rate\"]*params[\"lrratio\"],weight_decay=params[\"weight_decay\"])\n",
        "    # reg_gen_opt = optim.RMSprop(gen.parameters(), lr=params[\"learning_rate_reg\"])\n",
        "    # reg_disc_opt = optim.RMSprop(disc.parameters(), lr=params[\"learning_rate_reg\"])\n",
        "    \n",
        "elif params[\"optimizer\"] == \"RMSAdam\":\n",
        "    gen_opt  = optim.Adam(gen.parameters() , lr=params[\"learning_rate\"], betas=(0.9, 0.999), weight_decay=params[\"weight_decay\"])\n",
        "    disc_opt = optim.RMSprop(disc.parameters(), lr=params[\"learning_rate\"]*params[\"lrratio\"])\n",
        "    # reg_gen_opt = optim.Adam(gen.parameters(), lr=params[\"learning_rate_reg\"], betas=(0.9,0.999))\n",
        "    # reg_disc_opt = optim.RMSprop(disc.parameters(), lr=params[\"learning_rate_reg\"])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YRzyHoo43vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if params[\"LRtype\"]==\"Cyclic\":\n",
        "    scheduler_gen = CyclicLR(gen_opt, params[\"base_lr\"],params[\"learning_rate\"],\n",
        "                         step_size_up=params[\"stepsize_lr\"],\n",
        "                         step_size_down=params[\"stepsize_lr_down\"],\n",
        "                         cycle_momentum=False,mode=\"exp_range\",gamma = params[\"LRgamma\"])\n",
        "    scheduler_disc = CyclicLR(disc_opt, params[\"base_lr\"],params[\"learning_rate\"],\n",
        "                         step_size_up=params[\"stepsize_lr\"],\n",
        "                         step_size_down=params[\"stepsize_lr_down\"],\n",
        "                         cycle_momentum=False,mode=\"exp_range\",gamma = params[\"LRgamma\"])\n",
        "elif params[\"LRtype\"]==\"MStep\":\n",
        "    scheduler_gen = MultiStepLR(gen_opt, milestones=params[\"milestones\"], gamma=params[\"LRgamma\"])\n",
        "    scheduler_disc = MultiStepLR(disc_opt, milestones=params[\"milestones\"], gamma=params[\"LRgamma\"])\n",
        "elif params[\"LRtype\"]==\"Step\":\n",
        "    scheduler_gen = StepLR(gen_opt,step_size=params[\"stepsize_lr\"],gamma=params[\"LRgamma\"])\n",
        "    scheduler_disc = StepLR(disc_opt,step_size=params[\"stepsize_lr\"],gamma=params[\"LRgamma\"])\n",
        "elif params[\"LRtype\"]==\"CosA\":\n",
        "    scheduler_gen = CosineAnnealingLR(gen_opt,T_max=params[\"stepsize_lr\"],eta_min=params[\"base_lr\"])\n",
        "    scheduler_disc = CosineAnnealingLR(disc_opt,T_max=params[\"stepsize_lr\"],eta_min=params[\"base_lr\"])\n",
        "elif params[\"LRtype\"]==\"CosExp\":\n",
        "    scheduler_gen = CosineExpLR(gen_opt,T_max=params[\"stepsize_lr\"],eta_min=params[\"base_lr\"],gamma = params[\"LRgamma\"])\n",
        "    scheduler_disc = CosineExpLR(disc_opt,T_max=params[\"stepsize_lr\"],eta_min=params[\"base_lr\"],gamma = params[\"LRgamma\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpBbUF9DmDL2",
        "colab_type": "text"
      },
      "source": [
        "## Load scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9v-IZO8mDL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from prd_score import compute_prd, compute_prd_from_embedding, _prd_to_f_beta\n",
        "# from sklearn.metrics import auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7z0U53UNIV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from Regressor import Regressor, load_embedder\n",
        "# embedder = load_embedder('./embedder.tp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jumtrlNo2Gq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def D_train(PMResponse_b,ibatch,Condition_b=None,gen_input=None):\n",
        "    #=======================Train the discriminator=======================#\n",
        "    \n",
        "    disc_loss = 0\n",
        "    disc_real = 0\n",
        "    disc_fake = 0\n",
        "    \n",
        "    # disc_real = raw_real.mean()\n",
        "    if gen_input is not None:\n",
        "        PMResponse_gen = gen_input\n",
        "    else:\n",
        "        noise = torch.randn(PMResponse_b.shape[0], NOISEIMAGE_DIM, NOISEIMAGE_DIM).to(device)\n",
        "        PMResponse_gen = gen(noise,Condition_b).to(device)\n",
        "    \n",
        "    PMResponse_b   = add_instance_noise(PMResponse_b,params[\"noiselevel\"])\n",
        "    PMResponse_gen = add_instance_noise(PMResponse_gen,params[\"noiselevel\"])\n",
        "    raw_real,output_real = disc(PMResponse_b,Condition_b)\n",
        "    raw_fake,output_fake = disc(PMResponse_gen,Condition_b)\n",
        "    \n",
        "\n",
        "    if params[\"task\"]==\"WASSERSTEIN\":\n",
        "        disc_real = raw_real.mean()\n",
        "        disc_fake = raw_fake.mean()\n",
        "        if params[\"gp\"]:\n",
        "            if Condition_b is None:\n",
        "                penalty = calc_gradient_penalty(disc,\n",
        "                                                PMResponse_gen.data,\n",
        "                                                PMResponse_b.data,\n",
        "                                                None,\n",
        "                                                params[\"lambda_reg\"])\n",
        "            else:\n",
        "                penalty = calc_gradient_penalty(disc,\n",
        "                                                PMResponse_gen.data,\n",
        "                                                PMResponse_b.data,\n",
        "                                                Condition_b.data,\n",
        "                                                params[\"lambda_reg\"])\n",
        "            disc_loss = disc_fake-disc_real+penalty\n",
        "            experiment.log_metric(\"gradient_penalty\", penalty.data.item(),step=ibatch)\n",
        "        else:\n",
        "            penalty=0\n",
        "            disc_loss = disc_fake-disc_real\n",
        "            experiment.log_metric(\"gradient_penalty\", penalty,step=ibatch)\n",
        "        \n",
        "        experiment.log_metric(\"d_real\", disc_real.data.item(),step=ibatch)\n",
        "        experiment.log_metric(\"d_fake\", disc_fake.data.item(),step=ibatch)\n",
        "        \n",
        "\n",
        "    elif params[\"task\"] == \"CRAMER\":\n",
        "        noise_2 = torch.randn(len(EnergyDeposit_b), NOISEIMAGE_DIM, NOISEIMAGE_DIM).to(device)\n",
        "        EnergyDeposit_gen_2 = gen(noise_2, ParticleMomentum_ParticlePoint_ParticlePDG_b)\n",
        "        raw_fake_2,output_fake_2= disc(EnergyDeposit_gen_2.detach(),ParticleMomentum_ParticlePoint_ParticlePDG_b)\n",
        "        penalty = calc_gradient_penalty(disc,\n",
        "                                        EnergyDeposit_gen.data,\n",
        "                                        EnergyDeposit_b.data,\n",
        "                                        params[\"lambda_reg\"])\n",
        "        disc_loss = -critic(raw_real, raw_fake_2) + critic(raw_fake, raw_fake_2) + penalty\n",
        "        experiment.log_metric(\"gradient_penalty\", penalty.data.item(),step=ibatch)\n",
        "    elif params[\"task\"]==\"NORMAL\":\n",
        "        eps=1e-10\n",
        "        disc_real = F.logsigmoid(raw_real+eps).mean()\n",
        "        disc_fake = F.logsigmoid(1-raw_fake+eps).mean()\n",
        "        disc_loss = -disc_real-disc_fake\n",
        "        # print(disc_loss,disc_real,disc_fake)\n",
        "        experiment.log_metric(\"d_real\", disc_real.data.item(),step=ibatch)\n",
        "        experiment.log_metric(\"d_fake\", disc_fake.data.item(),step=ibatch)\n",
        "    elif params[\"task\"]==\"HINGE\":\n",
        "        eps=1e-10\n",
        "        disc_real = -torch.min(raw_real - 1, torch.zeros(raw_real.shape[0]).to(device)).mean()\n",
        "        disc_fake = -torch.min(-raw_fake - 1, torch.zeros(raw_fake.shape[0]).to(device)).mean()\n",
        "        disc_loss = disc_real+disc_fake\n",
        "        # print(disc_loss,disc_real,disc_fake)\n",
        "        experiment.log_metric(\"d_real\", disc_real.data.item(),step=ibatch)\n",
        "        experiment.log_metric(\"d_fake\", disc_fake.data.item(),step=ibatch)\n",
        "    disc_opt.zero_grad()\n",
        "    disc_loss.backward()\n",
        "    disc_opt.step()\n",
        "    # print(disc_loss.data.item())\n",
        "    \n",
        "    experiment.log_metric(\"d_loss\", disc_loss.data.item(),step=ibatch)\n",
        "        \n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHv4ORXp5BpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G_train(PMResponse_b,ibatch,Condition_b=None):\n",
        "    #=======================Train the generator=======================#\n",
        "    gen_opt.zero_grad()\n",
        "    gen_loss = 0\n",
        "    gen_real = 0\n",
        "    gen_prior = 0\n",
        "    gen_noise = 0\n",
        "    noise = torch.randn(PMResponse_b.shape[0], NOISEIMAGE_DIM,NOISEIMAGE_DIM).to(device)\n",
        "    PMResponse_gen = gen(noise,Condition_b)\n",
        "    PMResponse_gen = add_instance_noise(PMResponse_gen,params[\"noiselevel\"])\n",
        "    \n",
        "    raw_gen,output_gen = disc(PMResponse_gen,Condition_b)\n",
        "\n",
        "    if params[\"task\"]==\"WASSERSTEIN\" or params[\"task\"]==\"HINGE\":\n",
        "        gen_real = raw_gen.mean()\n",
        "        gen_loss = -gen_real\n",
        "        experiment.log_metric(\"g_real_loss\", gen_real.data.item(),step=ibatch)\n",
        "    elif params[\"task\"]==\"CRAMER\":\n",
        "        raw_real,output_real = disc(EnergyDeposit_b,ParticleMomentum_ParticlePoint_ParticlePDG_b)\n",
        "        noise_2 = torch.randn(PMResponse_b.shape[0], NOISEIMAGE_DIM, NOISEIMAGE_DIM).to(device)\n",
        "        EnergyDeposit_gen_2 = gen(noise_2, ParticleMomentum_ParticlePoint_ParticlePDG_b)\n",
        "        raw_fake_2,output_fake_2 = disc(EnergyDeposit_gen_2.detach(),ParticleMomentum_ParticlePoint_ParticlePDG_b)\n",
        "        gen_loss = gen_loss_func(raw_real,raw_gen,raw_fake_2)\n",
        "    elif params[\"task\"]==\"NORMAL\":\n",
        "        eps=1e-10\n",
        "        logp_gen_is_real = F.logsigmoid(raw_gen+eps).mean()\n",
        "        gen_loss = -logp_gen_is_real\n",
        "    \n",
        "    # The generator training wants to maximize the probability that\n",
        "    # the generated examples are labeled real by the descriminator\n",
        "    \n",
        "    # gen_real.backward()\n",
        "        # gen_loss.data.item(),gen_real.data.item(),gen_prior.data.item(),gen_noise.data.item()\n",
        "    experiment.log_metric(\"g_loss\", gen_loss.data.item(),step=ibatch)\n",
        "    \n",
        "             \n",
        "    gen_loss.backward()\n",
        "    gen_opt.step()\n",
        "    # disc.load(disc_back)\n",
        "    return PMResponse_gen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vaUJQhSEY4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Val_Eval(PMResponse_b,PMResponse_gen,epoch,Condition_b=None):\n",
        "    \n",
        "    # PMResponse_gen = add_instance_noise(PMResponse_gen,params[\"noiselevel\"])\n",
        "    raw_real,output_real = disc(PMResponse_b,Condition_b)\n",
        "    raw_fake,output_fake = disc(PMResponse_gen,Condition_b)\n",
        "    disc_real = raw_real.mean()\n",
        "    disc_fake = raw_fake.mean()\n",
        "    disc_loss = disc_fake-disc_real\n",
        "    experiment.log_metric(\"d_real\", disc_real.data.item(),step=epoch)\n",
        "    experiment.log_metric(\"d_fake\", disc_fake.data.item(),step=epoch)\n",
        "    experiment.log_metric(\"d_loss\", disc_loss.data.item(),step=epoch)\n",
        "    return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c18oWujomDL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LIPSITZ_WEIGHTS = False\n",
        "# ntrain_d = 1\n",
        "def run_training(epochs):\n",
        "    ibatch = 0 \n",
        "    prd_auc = []  \n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        first = True\n",
        "        with experiment.train():\n",
        "            experiment.log_metric(\"learning_rate\", scheduler_gen.get_lr(),step=epoch)\n",
        "            for Energy_b, UVW_b, SHW_b, PMResponse_b in train_loader:\n",
        "                Energy_b, UVW_b, SHW_b, PMResponse_b = Energy_b.to(device), \\\n",
        "                                                        UVW_b.to(device), \\\n",
        "                                                        SHW_b.to(device), \\\n",
        "                                                        PMResponse_b.to(device)\n",
        "                # ParticleMomentum_ParticlePoint_ParticlePDG_b = torch.cat([ParticleMomentum_b.to(device), ParticlePoint_b.to(device), ParticlePDG_b.to(device)], dim=1)\n",
        "                if params[\"test_sample\"]:\n",
        "                    PMResponse_b = Make_Sample(PMResponse_b.shape[0],PMResponse_b.shape[2],PMResponse_b.shape[3]).to(device)\n",
        "                if params[\"conditional\"]:\n",
        "                    Condition_b = UVW_b\n",
        "                else:\n",
        "                    Condition_b = None\n",
        "                    \n",
        "                for itrain in range(params[\"ntrain_d\"]):\n",
        "                    D_train(PMResponse_b,ibatch,Condition_b)\n",
        "                PMResponse_gen = G_train(PMResponse_b,ibatch,Condition_b)\n",
        "                if params[\"task\"]==\"WASSERSTEIN\" and not params[\"gp\"]:\n",
        "                    [p.data.clamp_(-params[\"lipsitzbound\"], params[\"lipsitzbound\"]) for p in disc.parameters()]\n",
        "            \n",
        "                # break    \n",
        "                clear_output()\n",
        "                if ibatch %100 ==2:\n",
        "                    plt.figure(figsize=(15,12))\n",
        "                    grid = plt.GridSpec(2, 3, wspace=0.4, hspace=0.3)\n",
        "                    for event in range(3):\n",
        "                        plt.subplot(grid[0,event])\n",
        "                        plt.imshow(PMResponse_b[event][0].cpu().detach().numpy(),vmin=0,origin='lower')\n",
        "                        plt.title(\"(%f,%f,%f)\"%(UVW_b[event][0],UVW_b[event][1],UVW_b[event][2]))\n",
        "                        plt.colorbar()\n",
        "                        plt.subplot(grid[1, event])\n",
        "                        plt.imshow(PMResponse_gen[event][0].cpu().detach().numpy(),vmin=0,origin='lower')\n",
        "                        plt.title(\"(%f,%f,%f)\"%(UVW_b[event][0],UVW_b[event][1],UVW_b[event][2]))\n",
        "                        plt.colorbar()\n",
        "                    \n",
        "                    experiment.log_figure(figure_name=\"status%d\"%(ibatch),figure=plt,step =ibatch)\n",
        "                    time.sleep(0.5)\n",
        "                    plt.close()\n",
        "    #             plt.show()\n",
        "                ibatch += 1\n",
        "        \n",
        "        with experiment.test():\n",
        "            for Energy_b, UVW_b, SHW_b, PMResponse_b in validation_loader:\n",
        "                Energy_b, UVW_b, SHW_b, PMResponse_b = Energy_b.to(device), \\\n",
        "                                                        UVW_b.to(device), \\\n",
        "                                                        SHW_b.to(device), \\\n",
        "                                                        PMResponse_b.to(device)\n",
        "                if params[\"test_sample\"]:\n",
        "                    PMResponse_b = Make_Sample(PMResponse_b.shape[0],PMResponse_b.shape[2],PMResponse_b.shape[3]).to(device)\n",
        "                if params[\"conditional\"]:\n",
        "                    Condition_b = UVW_b\n",
        "                else:\n",
        "                    Condition_b = None\n",
        "                noise = torch.randn(PMResponse_b.shape[0], NOISEIMAGE_DIM,NOISEIMAGE_DIM).to(device)\n",
        "                PMResponse_gen = gen(noise,Condition_b).to(device)\n",
        "                Val_Eval(PMResponse_b,PMResponse_gen,epoch,Condition_b)\n",
        "                break\n",
        "            \n",
        "        scheduler_gen.step()\n",
        "        scheduler_disc.step()\n",
        "        \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "zPLcnlKhmDMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with experiment.train():\n",
        "    run_training(params[\"epochs\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT2fiNDMmDMJ",
        "colab_type": "text"
      },
      "source": [
        "#### Transfer generator on CPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTumKz8smDMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_cpu = ModelGConvTranspose(z_dim=NOISEIMAGE_DIM,MomentumPointPDGScale = MomentumPointPDGScale,EnergyScale = EnergyDepositScale)\n",
        "# generator_cpu.load_state_dict(gen.state_dict())\n",
        "generator_cpu.load_state_dict(torch.load('/gdrive/My Drive/gan80.pt'))\n",
        "# generator_cpu.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrzMuZGzmDMM",
        "colab_type": "text"
      },
      "source": [
        "### Save model on disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXwtnaSBmDMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(generator_cpu.state_dict(), './gan_middle.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nITR2bZwmDMO",
        "colab_type": "text"
      },
      "source": [
        "## Making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihAqZQxvmDMP",
        "colab_type": "text"
      },
      "source": [
        "#### Validation predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rVhVrubhmDMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_val = np.load(val_data_path, allow_pickle=True)\n",
        "ParticleMomentum_val = torch.tensor(data_val['ParticleMomentum']).float()\n",
        "ParticlePoint_val = torch.tensor(data_val['ParticlePoint'][:, :2]).float()\n",
        "ParticlePDG_val = torch.tensor(data_val['ParticlePDG'].reshape(-1,1)).float()\n",
        "ParticleMomentum_ParticlePoint_ParticlePDG_val = torch.cat([ParticleMomentum_val, ParticlePoint_val,ParticlePDG_val], dim=1)\n",
        "calo_dataset_val = utils.TensorDataset(ParticleMomentum_ParticlePoint_ParticlePDG_val)\n",
        "calo_dataloader_val = torch.utils.data.DataLoader(calo_dataset_val, batch_size=1024, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    EnergyDeposit_val = []\n",
        "    for ParticleMomentum_ParticlePoint_ParticlePDG_val_batch in tqdm(calo_dataloader_val):\n",
        "        noise = torch.randn(len(ParticleMomentum_ParticlePoint_ParticlePDG_val_batch[0]), NOISEIMAGE_DIM,NOISEIMAGE_DIM)\n",
        "        EnergyDeposit_val_batch = generator_cpu(noise, ParticleMomentum_ParticlePoint_ParticlePDG_val_batch[0]).detach().numpy()\n",
        "        EnergyDeposit_val.append(EnergyDeposit_val_batch)\n",
        "    np.savez_compressed('./data_val_prediction.npz', \n",
        "                        EnergyDeposit=np.concatenate(EnergyDeposit_val, axis=0).reshape(-1, 30, 30))\n",
        "\n",
        "    del EnergyDeposit_val\n",
        "del data_val; del ParticleMomentum_val; del ParticlePoint_val; del ParticleMomentum_ParticlePoint_ParticlePDG_val;\n",
        "del calo_dataset_val; calo_dataloader_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz2T9U3-mDMS",
        "colab_type": "text"
      },
      "source": [
        "#### Test predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "666U1Q_smDMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = np.load(test_data_path, allow_pickle=True)\n",
        "ParticleMomentum_test = torch.tensor(data_test['ParticleMomentum']).float()\n",
        "ParticlePoint_test = torch.tensor(data_test['ParticlePoint'][:, :2]).float()\n",
        "ParticlePDG_test = torch.tensor(data_test['ParticlePDG'].reshape(-1,1)).float()\n",
        "ParticleMomentum_ParticlePoint_ParticlePDG_test = torch.cat([ParticleMomentum_test, ParticlePoint_test, ParticlePDG_test], dim=1)\n",
        "calo_dataset_test = utils.TensorDataset(ParticleMomentum_ParticlePoint_ParticlePDG_test)\n",
        "calo_dataloader_test = torch.utils.data.DataLoader(calo_dataset_test, batch_size=1024, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    EnergyDeposit_test = []\n",
        "    for ParticleMomentum_ParticlePoint_ParticlePDG_test_batch in tqdm(calo_dataloader_test):\n",
        "        noise = torch.randn(len(ParticleMomentum_ParticlePoint_ParticlePDG_test_batch[0]), NOISE_DIM)\n",
        "        EnergyDeposit_test_batch = generator_cpu(noise, ParticleMomentum_ParticlePoint_ParticlePDG_test_batch[0]).detach().numpy()\n",
        "        EnergyDeposit_test.append(EnergyDeposit_test_batch)\n",
        "    np.savez_compressed('./data_test_prediction.npz', \n",
        "                        EnergyDeposit=np.concatenate(EnergyDeposit_test, axis=0).reshape(-1, 30, 30))\n",
        "\n",
        "    del EnergyDeposit_test\n",
        "del data_test; del ParticleMomentum_test; del ParticlePoint_test; del ParticleMomentum_ParticlePoint_ParticlePDG_test;\n",
        "del calo_dataset_test; calo_dataloader_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AIKCQMtmDMU",
        "colab_type": "text"
      },
      "source": [
        "## `zip-zip` files together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvbj0nhzmDMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip solution.zip data_val_prediction.npz data_test_prediction.npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG-4EvGOmDMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink('./solution.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGp0K2LrmDMY",
        "colab_type": "text"
      },
      "source": [
        "# A few words about metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_j_38JamDMa",
        "colab_type": "text"
      },
      "source": [
        "### Lets generate some fake data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47UHZk7B0Lei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b, ParticlePDG_b in validation_loader:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kyqaIyhmDMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = torch.randn(len(ParticleMomentum_b), NOISE_DIM)\n",
        "with torch.no_grad():\n",
        "    ParticleMomentum_ParticlePoint_ParticlePDG = torch.cat([ParticleMomentum_b, \n",
        "                                                ParticlePoint_b,\n",
        "                                                ParticlePDG_b], dim=1)\n",
        "    EnergyDeposit_gen = generator_cpu(noise, ParticleMomentum_ParticlePoint_ParticlePDG.cpu())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s353zPylmDMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit_gen = EnergyDeposit_gen.detach().cpu().numpy().reshape(-1, 30, 30)\n",
        "EnergyDeposit_b = EnergyDeposit_b.detach().cpu().numpy().reshape(-1, 30, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TD90ylsmDMd",
        "colab_type": "text"
      },
      "source": [
        "#### Plot one image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxhjGZGYmDMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(EnergyDeposit_gen[2])\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTftFOhSmDMg",
        "colab_type": "text"
      },
      "source": [
        "## Calculate PRD score between these batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWEusQu0mDMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Regressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Regressor, self).__init__()\n",
        "        self.batchnorm0 = nn.BatchNorm2d(1)\n",
        "        self.conv1 = nn.Conv2d(1, 16, 2, stride=2)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 2, stride=2)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 2, stride=2)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 2)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        \n",
        "        self.fc1 = nn.Linear(256, 256) \n",
        "        self.batchnorm4 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 2 + 3)\n",
        "        self.fc5 = nn.Linear(64, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.batchnorm0(self.dropout(x))\n",
        "        x = self.batchnorm1(self.dropout(F.relu(self.conv1(x))))\n",
        "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
        "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
        "        x = F.relu(self.conv4(x)) # 64, 5, 5\n",
        "        x = x.view(len(x), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm4(self.dropout(F.relu(self.fc1(x))))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        return self.fc4(x), self.fc5(x)\n",
        "    \n",
        "    def get_encoding(self, x):\n",
        "        x = self.batchnorm0(self.dropout(x))\n",
        "        x = self.batchnorm1(self.dropout(F.relu(self.conv1(x))))\n",
        "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
        "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
        "        x = F.relu(self.conv4(x)) # 64, 5, 5\n",
        "        x = x.view(len(x), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm4(self.dropout(F.relu(self.fc1(x))))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "def load_embedder(path):\n",
        "    embedder = torch.load(path)\n",
        "    embedder.eval()\n",
        "    return embedder\n",
        "\n",
        "embedder = load_embedder('./embedder.tp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd63IOwVmDMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_real = embedder.get_encoding(torch.tensor(EnergyDeposit_b).float().view(-1, 1, 30, 30)).detach().numpy()\n",
        "data_fake = embedder.get_encoding(torch.tensor(EnergyDeposit_gen).float().view(-1, 1, 30, 30)).detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGM2uI_qmDMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_pr_aucs(precisions, recalls):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    pr_aucs = []\n",
        "    for i in range(len(recalls)):\n",
        "        plt.step(recalls[i], precisions[i], color='b', alpha=0.2,  label='PR-AUC={}'.format(auc(precisions[i], recalls[i])))\n",
        "        pr_aucs.append(auc(precisions[i], recalls[i]))\n",
        "    plt.step(np.mean(recalls, axis=0), np.mean(precisions, axis=0), color='r', alpha=1,  label='average')\n",
        "    plt.fill_between(np.mean(recalls, axis=0), \n",
        "                     np.mean(precisions, axis=0) - np.std(precisions, axis=0) * 3,\n",
        "                     np.mean(precisions, axis=0) + np.std(precisions, axis=0) * 3, color='g', alpha=0.2,  label='std')\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "\n",
        "    # plt.ylim([0.0, 1.05])\n",
        "    # plt.xlim([0.0, 1.0])\n",
        "    print(np.mean(pr_aucs), np.std(pr_aucs))\n",
        "    plt.legend()\n",
        "    \n",
        "    return pr_aucs\n",
        "\n",
        "def calc_pr_rec(data_real, data_fake, num_clusters=20, num_runs=10, NUM_RUNS=10):\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    for i in tqdm(range(NUM_RUNS)):\n",
        "        precision, recall = compute_prd_from_embedding(data_real, data_fake, num_clusters=num_clusters, num_runs=num_runs)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "    return precisions, recalls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NApjdKVmDMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precisions, recalls = calc_pr_rec(data_real, data_fake, num_clusters=100, num_runs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0D4-j__mDMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs = plot_pr_aucs(precisions, recalls)\n",
        "plt.title('Num_clusters={}, num_runs={}, first third'.format(100, 20))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erF_MpJ_mDMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXkiQuGlmDMs",
        "colab_type": "text"
      },
      "source": [
        "## Physical metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI_33EaxmDMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.lines as mlines\n",
        "def newline(p1, p2):\n",
        "    ax = plt.gca()\n",
        "    xmin, xmax = ax.get_xbound()\n",
        "\n",
        "    if(p2[0] == p1[0]):\n",
        "        xmin = xmax = p1[0]\n",
        "        ymin, ymax = ax.get_ybound()\n",
        "    else:\n",
        "        ymax = p1[1]+(p2[1]-p1[1])/(p2[0]-p1[0])*(xmax-p1[0])\n",
        "        ymin = p1[1]+(p2[1]-p1[1])/(p2[0]-p1[0])*(xmin-p1[0])\n",
        "\n",
        "    l = mlines.Line2D([xmin,xmax], [ymin,ymax])\n",
        "    ax.add_line(l)\n",
        "    return l\n",
        "\n",
        "def plot_axes_for_shower(ecal, point, p):\n",
        "    x = np.linspace(-14.5, 14.5, 30)\n",
        "    y = np.linspace(-14.5, 14.5, 30)\n",
        "\n",
        "    xx, yy = np.meshgrid(x, y)\n",
        "    zoff = 25.\n",
        "    ipic = 3\n",
        "    orth = np.array([-p[1], p[0]])\n",
        "\n",
        "    pref = point[:2] + p[:2] * zoff / p[2]\n",
        "\n",
        "    p1 = pref - 10 * p[:2]\n",
        "    p2 = pref + 10 * p[:2]\n",
        "    p3 = pref - 10 * orth\n",
        "    p4 = pref + 10 * orth\n",
        "\n",
        "    plt.contourf(xx, yy, np.log(ecal + 1), cmap=plt.cm.inferno)\n",
        "    newline(p1, p2)\n",
        "    newline(p3, p4)\n",
        "    plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR08nJ9gmDMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 2\n",
        "plot_axes_for_shower(EnergyDeposit[idx], point=ParticlePoint[idx].detach().numpy(),\n",
        "                     p=ParticleMomentum[idx].detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUCqH0_SmDMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from calogan_metrics import get_assymetry, get_shower_width, get_sparsity_level"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbvzfsYUmDM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assym = get_assymetry(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=False)\n",
        "assym_ortho = get_assymetry(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=True)\n",
        "sh_width = get_shower_width(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=False)\n",
        "sh_width_ortho = get_shower_width(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=True)\n",
        "sparsity_level = get_sparsity_level(EnergyDeposit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eJLvn3EmDM2",
        "colab_type": "text"
      },
      "source": [
        "## Longitudual cluster asymmetry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEORbnE7mDM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(font_scale=2)\n",
        "plt.hist(assym, bins=50, range=[-1, 1], color='red', alpha=0.3, normed=True, label='MC');\n",
        "plt.xlabel('Longitudual cluster asymmetry')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15wFghYcmDM3",
        "colab_type": "text"
      },
      "source": [
        "## Transverse cluster asymmetry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfge5LTMmDM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(font_scale=2)\n",
        "plt.hist(assym_ortho, bins=50, range=[-1, 1], color='red', alpha=0.3, normed=True, label='MC');\n",
        "plt.xlabel('Transverse cluster asymmetry')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4lWh8VAmDM5",
        "colab_type": "text"
      },
      "source": [
        "## Cluster longitudual width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB27rAtImDM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(sh_width, bins=50, range=[0, 15], normed=True, alpha=0.3, color='red', label='MC');\n",
        "plt.title('Shower longitudial width')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Cluster longitudual width [cm]')\n",
        "plt.ylabel('Arbitrary units')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC-HiFBamDM7",
        "colab_type": "text"
      },
      "source": [
        "## Cluster trasverse width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBIu8gwLmDM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(sh_width_ortho, bins=50, range=[0,10], normed=True, alpha=0.3, color='blue', label='MC');\n",
        "#plt.title('Shower transverse width')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Cluster trasverse width [cm]')\n",
        "plt.ylabel('Arbitrary units')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pFbBYvOmDNA",
        "colab_type": "text"
      },
      "source": [
        "## Sparsity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob53fPO_mDNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphas = np.log(np.logspace(-5, -1, 20))\n",
        "means_r = np.mean(sparsity_level, axis=1)\n",
        "stddev_r = np.std(sparsity_level, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QygKaRldmDNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(alphas, means_r, color='red')\n",
        "plt.fill_between(alphas, means_r-stddev_r, means_r+stddev_r, color='red', alpha=0.3)\n",
        "plt.legend(['MC'])\n",
        "plt.title('Sparsity')\n",
        "plt.xlabel('log10(Threshold/GeV)')\n",
        "plt.ylabel('Fraction of cells above threshold')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-imUBMEmDND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from calogan_metrics import get_physical_stats\n",
        "real_phys_stats = get_physical_stats(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy())\n",
        "gen_phys_stats = get_physical_stats(EnergyDeposit_gen, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp_s9vGcmDNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precisions, recalls = calc_pr_rec(real_phys_stats, gen_phys_stats, num_clusters=100, num_runs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btvs99JKmDNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs = plot_pr_aucs(precisions, recalls)\n",
        "plt.title('Num_clusters={}, num_runs={}, first third'.format(100, 20))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOyBgN-4mDNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}